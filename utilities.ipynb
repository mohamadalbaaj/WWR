{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.3' (you have '2.0.2'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.ops import nms\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import rich\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 250\n"
     ]
    }
   ],
   "source": [
    "class FacadeDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotations_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def load_annotations(self, annotation_file):\n",
    "        with open(annotation_file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for shape in data[\"shapes\"]:\n",
    "            if shape[\"label\"] == \"window\":\n",
    "                points = shape[\"points\"]\n",
    "                \n",
    "                # Calculate bounding box from polygon points\n",
    "                x_coords = [p[0] for p in points]\n",
    "                y_coords = [p[1] for p in points]\n",
    "                x_min = min(x_coords)\n",
    "                y_min = min(y_coords)\n",
    "                x_max = max(x_coords)\n",
    "                y_max = max(y_coords)\n",
    "                \n",
    "                # Bounding box format: [x_min, y_min, width, height]\n",
    "                box = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
    "                boxes.append(box)\n",
    "                labels.append(1)  # Use 1 for \"window\" category label\n",
    "\n",
    "        return {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        annotation_path = os.path.join(self.annotations_dir, f\"{os.path.splitext(img_name)[0]}.json\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        annotations = self.load_annotations(annotation_path)\n",
    "\n",
    "        # Convert bounding boxes and labels to tensors\n",
    "        boxes = torch.tensor(annotations[\"boxes\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(annotations[\"labels\"], dtype=torch.int64)\n",
    "\n",
    "        if self.transform:  \n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "        return image, target\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Directories for training\n",
    "train_image_dir = os.path.join(\"ZJU_dataset_2\", \"images\")\n",
    "train_annotations_dir = os.path.join(\"ZJU_dataset_2\", \"annotation\")\n",
    "\n",
    "# Create dataset\n",
    "initial_dataset = FacadeDataset(train_image_dir, train_annotations_dir, transform=transform)\n",
    "\n",
    "# print(\"Dataset :\", dataset[0])\n",
    "\n",
    "print(\"Dataset length:\", len(initial_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed and saved!\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation pipeline\n",
    "augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    # A.RandomBrightnessContrast(p=0.2),\n",
    "    # A.Rotate(limit=10, p=0.3, border_mode=cv2.BORDER_CONSTANT),  # Ensure rotated bbox stays valid\n",
    "    # A.Blur(p=0.1),\n",
    "    # A.MotionBlur(p=0.1),\n",
    "    # A.GaussNoise(p=0.1),\n",
    "    # A.Resize(256, 256),  # Resize for consistency\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"], check_each_transform=True, min_visibility=0.3))\n",
    "\n",
    "# Function to apply augmentation\n",
    "def augment_and_save(dataset, save_dir, aug_count=2):\n",
    "    image_save_dir = os.path.join(save_dir, \"images\")\n",
    "    annotation_save_dir = os.path.join(save_dir, \"annotation\")\n",
    "    os.makedirs(image_save_dir, exist_ok=True)\n",
    "    os.makedirs(annotation_save_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        image, target = dataset[i]\n",
    "        image_np = np.array(image.permute(1, 2, 0))  # Convert to NumPy array\n",
    "        boxes = target[\"boxes\"].tolist()\n",
    "        labels = target[\"labels\"].tolist()\n",
    "\n",
    "        # Convert from COCO format [x_min, y_min, width, height] â†’ Pascal VOC [x_min, y_min, x_max, y_max]\n",
    "        boxes = [[b[0], b[1], b[0] + b[2], b[1] + b[3]] for b in boxes]\n",
    "\n",
    "        for j in range(aug_count):\n",
    "            augmented = augmentations(image=image_np, bboxes=boxes, labels=labels)\n",
    "            aug_image = augmented[\"image\"]\n",
    "            aug_boxes = augmented[\"bboxes\"]\n",
    "\n",
    "            # Convert back to COCO format if needed\n",
    "            aug_boxes = [[b[0], b[1], b[2] - b[0], b[3] - b[1]] for b in aug_boxes]\n",
    "\n",
    "            # Skip if all bounding boxes are removed\n",
    "            if len(aug_boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            # Convert back to PIL Image\n",
    "            aug_image_pil = transforms.ToPILImage()(aug_image)\n",
    "\n",
    "            # Save augmented image\n",
    "            new_filename = f\"{i}_aug{j}.jpg\"\n",
    "            aug_image_pil.save(os.path.join(image_save_dir, new_filename))\n",
    "\n",
    "            # Save augmented annotations\n",
    "            aug_annotation = {\n",
    "                \"imagePath\": new_filename,  # Add image filename to JSON\n",
    "                \"shapes\": [\n",
    "                    {\"label\": \"window\", \"points\": [[x, y] for x, y in [[b[0], b[1]], [b[0] + b[2], b[1] + b[3]]]]}\n",
    "                    for b in aug_boxes\n",
    "                ]\n",
    "            }\n",
    "            with open(os.path.join(annotation_save_dir, f\"{i}_aug{j}.json\"), \"w\") as f:\n",
    "                json.dump(aug_annotation, f)\n",
    "\n",
    "    print(\"Augmentation completed and saved!\")\n",
    "\n",
    "# Run augmentation process\n",
    "augment_and_save(initial_dataset, save_dir=\"ZJU_dataset_augmented\", aug_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset merging completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "base_dir = \"ZJU_dataset_2_full\"\n",
    "full_image_dir = os.path.join(base_dir, \"images\")\n",
    "full_annotations_dir = os.path.join(base_dir, \"annotation\")\n",
    "\n",
    "# Create new dataset directories\n",
    "os.makedirs(full_image_dir, exist_ok=True)\n",
    "os.makedirs(full_annotations_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy files from source to destination\n",
    "def copy_files(src_dir, dst_dir):\n",
    "    if os.path.exists(src_dir):\n",
    "        for file_name in os.listdir(src_dir):\n",
    "            src_path = os.path.join(src_dir, file_name)\n",
    "            dst_path = os.path.join(dst_dir, file_name)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Copy images and annotations from both datasets\n",
    "copy_files(\"ZJU_dataset_2/images\", full_image_dir)\n",
    "copy_files(\"ZJU_dataset_augmented/images\", full_image_dir)\n",
    "copy_files(\"ZJU_dataset_2/annotation\", full_annotations_dir)\n",
    "copy_files(\"ZJU_dataset_augmented/annotation\", full_annotations_dir)\n",
    "\n",
    "print(\"Dataset merging completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draw segmentations on the images to create masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories\n",
    "image_directory = os.path.join(\"ZJU_dataset_2_full\", \"images\")\n",
    "input_directory = os.path.join(\"ZJU_dataset_2_full\", \"annotation\")\n",
    "output_directory = os.path.join(\"ZJU_dataset_2_full\", \"masks\")\n",
    "\n",
    "# Create the masks directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over each JSON file in the input directory\n",
    "for json_file in os.listdir(input_directory):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(input_directory, json_file)\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Get the image details from the JSON file\n",
    "    image_filename = data['imagePath']\n",
    "    image_path = os.path.join(image_directory, image_filename)\n",
    "\n",
    "    # Check if the image file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Load the image to get its dimensions\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "\n",
    "    # Create a blank mask\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    # Draw the polygons on the mask\n",
    "    for shape in data['shapes']:\n",
    "        if shape['label'] == 'window':  # Check if the label is 'window'\n",
    "            polygon = [(x, y) for x, y in shape['points']]\n",
    "            draw.polygon(polygon, outline=50, fill=255)\n",
    "\n",
    "    # Save the mask\n",
    "    mask_filename = f\"mask_{image_filename.replace('.jpg', '.png')}\"\n",
    "    mask_path = os.path.join(output_directory, mask_filename)\n",
    "    mask.save(mask_path)\n",
    "    print(f\"Saved mask for {image_filename} to {mask_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
