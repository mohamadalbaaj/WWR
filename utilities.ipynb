{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.4' (you have '2.0.2'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.ops import nms\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import rich\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacadeDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotations_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def load_annotations(self, annotation_file):\n",
    "        with open(annotation_file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for shape in data[\"shapes\"]:\n",
    "            if shape[\"label\"] == \"window\":\n",
    "                points = shape[\"points\"]\n",
    "                \n",
    "                # Calculate bounding box from polygon points\n",
    "                x_coords = [p[0] for p in points]\n",
    "                y_coords = [p[1] for p in points]\n",
    "                x_min = min(x_coords)\n",
    "                y_min = min(y_coords)\n",
    "                x_max = max(x_coords)\n",
    "                y_max = max(y_coords)\n",
    "                \n",
    "                # Bounding box format: [x_min, y_min, width, height]\n",
    "                box = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
    "                boxes.append(box)\n",
    "                labels.append(1)  # Use 1 for \"window\" category label\n",
    "\n",
    "        return {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        annotation_path = os.path.join(self.annotations_dir, f\"{os.path.splitext(img_name)[0]}.json\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        annotations = self.load_annotations(annotation_path)\n",
    "\n",
    "        # Convert bounding boxes and labels to tensors\n",
    "        boxes = torch.tensor(annotations[\"boxes\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(annotations[\"labels\"], dtype=torch.int64)\n",
    "\n",
    "        if self.transform:  \n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "        return image, target\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Directories for training\n",
    "train_image_dir = os.path.join(\"ZJU_dataset\", \"images\")\n",
    "train_annotations_dir = os.path.join(\"ZJU_dataset\", \"annotation\")\n",
    "\n",
    "# Create dataset\n",
    "initial_dataset = FacadeDataset(train_image_dir, train_annotations_dir, transform=transform)\n",
    "\n",
    "# print(\"Dataset :\", dataset[0])\n",
    "\n",
    "print(\"Dataset length:\", len(initial_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipeline\n",
    "augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    # A.RandomBrightnessContrast(p=0.2),\n",
    "    # A.Rotate(limit=10, p=0.3, border_mode=cv2.BORDER_CONSTANT),  # Ensure rotated bbox stays valid\n",
    "    # A.Blur(p=0.1),\n",
    "    # A.MotionBlur(p=0.1),\n",
    "    # A.GaussNoise(p=0.1),\n",
    "    # A.Resize(256, 256),  # Resize for consistency\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"], check_each_transform=True, min_visibility=0.3))\n",
    "\n",
    "# Function to apply augmentation\n",
    "def augment_and_save(dataset, save_dir, aug_count=2):\n",
    "    image_save_dir = os.path.join(save_dir, \"images\")\n",
    "    annotation_save_dir = os.path.join(save_dir, \"annotation\")\n",
    "    os.makedirs(image_save_dir, exist_ok=True)\n",
    "    os.makedirs(annotation_save_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        image, target = dataset[i]\n",
    "        image_np = np.array(image.permute(1, 2, 0))  # Convert to NumPy array\n",
    "        boxes = target[\"boxes\"].tolist()\n",
    "        labels = target[\"labels\"].tolist()\n",
    "\n",
    "        # Convert from COCO format [x_min, y_min, width, height] â†’ Pascal VOC [x_min, y_min, x_max, y_max]\n",
    "        boxes = [[b[0], b[1], b[0] + b[2], b[1] + b[3]] for b in boxes]\n",
    "\n",
    "        for j in range(aug_count):\n",
    "            augmented = augmentations(image=image_np, bboxes=boxes, labels=labels)\n",
    "            aug_image = augmented[\"image\"]\n",
    "            aug_boxes = augmented[\"bboxes\"]\n",
    "\n",
    "            # Convert back to COCO format if needed\n",
    "            aug_boxes = [[b[0], b[1], b[2] - b[0], b[3] - b[1]] for b in aug_boxes]\n",
    "\n",
    "            # Skip if all bounding boxes are removed\n",
    "            if len(aug_boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            # Convert back to PIL Image\n",
    "            aug_image_pil = transforms.ToPILImage()(aug_image)\n",
    "\n",
    "            # Save augmented image\n",
    "            new_filename = f\"{i}_aug{j}.jpg\"\n",
    "            aug_image_pil.save(os.path.join(image_save_dir, new_filename))\n",
    "\n",
    "            # Save augmented annotations\n",
    "            aug_annotation = {\n",
    "                \"imagePath\": new_filename,  # Add image filename to JSON\n",
    "                \"shapes\": [\n",
    "                    {\"label\": \"window\", \"points\": [[x, y] for x, y in [[b[0], b[1]], [b[0] + b[2], b[1] + b[3]]]]}\n",
    "                    for b in aug_boxes\n",
    "                ]\n",
    "            }\n",
    "            with open(os.path.join(annotation_save_dir, f\"{i}_aug{j}.json\"), \"w\") as f:\n",
    "                json.dump(aug_annotation, f)\n",
    "\n",
    "    print(\"Augmentation completed and saved!\")\n",
    "\n",
    "# Run augmentation process\n",
    "augment_and_save(initial_dataset, save_dir=\"ZJU_dataset_augmented\", aug_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "base_dir = \"ZJU_dataset_full\"\n",
    "full_image_dir = os.path.join(base_dir, \"images\")\n",
    "full_annotations_dir = os.path.join(base_dir, \"annotation\")\n",
    "\n",
    "# Create new dataset directories\n",
    "os.makedirs(full_image_dir, exist_ok=True)\n",
    "os.makedirs(full_annotations_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy files from source to destination\n",
    "def copy_files(src_dir, dst_dir):\n",
    "    if os.path.exists(src_dir):\n",
    "        for file_name in os.listdir(src_dir):\n",
    "            src_path = os.path.join(src_dir, file_name)\n",
    "            dst_path = os.path.join(dst_dir, file_name)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Copy images and annotations from both datasets\n",
    "copy_files(\"ZJU_dataset/images\", full_image_dir)\n",
    "copy_files(\"ZJU_dataset_augmented/images\", full_image_dir)\n",
    "copy_files(\"ZJU_dataset/annotation\", full_annotations_dir)\n",
    "copy_files(\"ZJU_dataset_augmented/annotation\", full_annotations_dir)\n",
    "\n",
    "print(\"Dataset merging completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draw segmentations on the images to create masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories\n",
    "image_directory = os.path.join(\"ZJU_dataset_full\", \"images\")\n",
    "input_directory = os.path.join(\"ZJU_dataset_full\", \"annotation\")\n",
    "output_directory = os.path.join(\"ZJU_dataset_full\", \"masks\")\n",
    "\n",
    "# Create the masks directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over each JSON file in the input directory\n",
    "for json_file in os.listdir(input_directory):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(input_directory, json_file)\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Get the image details from the JSON file\n",
    "    image_filename = data['imagePath']\n",
    "    image_path = os.path.join(image_directory, image_filename)\n",
    "\n",
    "    # Check if the image file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Load the image to get its dimensions\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "\n",
    "    # Create a blank mask\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    for shape in data['shapes']:\n",
    "        if shape['label'] == 'window':  # Check if the label is 'window'\n",
    "            points = shape['points']\n",
    "\n",
    "            # Check if only two points are provided (top-left and bottom-right)\n",
    "            if len(points) == 2:\n",
    "                (x1, y1), (x2, y2) = points\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Convert to four-point rectangle\n",
    "                polygon = [(x1, y1), (x1, y2), (x2, y2), (x2, y1)]\n",
    "            else:\n",
    "                # If already four points, just convert them to integers\n",
    "                polygon = [((x), (y)) for x, y in points]\n",
    "\n",
    "            draw.polygon(polygon, outline=50, fill=255)\n",
    "\n",
    "\n",
    "    # Save the mask\n",
    "    mask_filename = f\"mask_{image_filename.replace('.jpg', '.png')}\"\n",
    "    mask_path = os.path.join(output_directory, mask_filename)\n",
    "    mask.save(mask_path)\n",
    "    print(f\"Saved mask for {image_filename} to {mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create the masks for the evalution dataset for the semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Define the directories\n",
    "image_directory = \"Evaluation_dataset\"\n",
    "annotation_file = \"Evaluation_dataset/merged.json\"\n",
    "output_directory = \"Evaluation_dataset/masks\"\n",
    "\n",
    "# Create the masks directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Load the JSON file\n",
    "with open(annotation_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a mapping of image_id to filename and dimensions\n",
    "image_info = {img['id']: (img['file_name'], img['width'], img['height']) for img in data['images']}\n",
    "\n",
    "# Group annotations by image_id\n",
    "annotations_by_image = {}\n",
    "for annotation in data['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "    if image_id not in annotations_by_image:\n",
    "        annotations_by_image[image_id] = []\n",
    "    annotations_by_image[image_id].append(annotation)\n",
    "\n",
    "# Process each image\n",
    "for image_id, annotations in annotations_by_image.items():\n",
    "    # Get image filename and dimensions\n",
    "    if image_id not in image_info:\n",
    "        continue\n",
    "\n",
    "    image_filename, width, height = image_info[image_id]\n",
    "    image_path = os.path.join(image_directory, image_filename)\n",
    "\n",
    "    # Check if the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Create a blank mask\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    # Draw all window annotations on the mask\n",
    "    for annotation in annotations:\n",
    "        if 'segmentation' in annotation and len(annotation['segmentation']) > 0:\n",
    "            for segment in annotation['segmentation']:\n",
    "                polygon = [(segment[i], segment[i + 1]) for i in range(0, len(segment), 2)]\n",
    "                draw.polygon(polygon, outline=50, fill=255)\n",
    "\n",
    "    # Save the mask\n",
    "    mask_filename = f\"mask_{image_filename.replace('.jpg', '.png')}\"\n",
    "    mask_path = os.path.join(output_directory, mask_filename)\n",
    "    mask.save(mask_path)\n",
    "    # print(f\"Saved mask for {image_filename} with {len(annotations)} windows to {mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split the dataset & create annotation based on yolo requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for input data\n",
    "image_dir = os.path.join(\"ZJU_dataset\", \"images\")\n",
    "annotation_dir = os.path.join(\"ZJU_dataset\", \"annotation\")\n",
    "\n",
    "# Paths for YOLO-formatted dataset\n",
    "output_dir = \"datasets\"\n",
    "train_images_dir = os.path.join(output_dir, \"train\", \"images\")\n",
    "train_labels_dir = os.path.join(output_dir, \"train\", \"labels\")\n",
    "val_images_dir = os.path.join(output_dir, \"val\", \"images\")\n",
    "val_labels_dir = os.path.join(output_dir, \"val\", \"labels\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "# Function to convert annotations to YOLO format\n",
    "def convert_to_yolo_format(annotation_path, image_width, image_height):\n",
    "    with open(annotation_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    yolo_annotations = []\n",
    "    for shape in data[\"shapes\"]:\n",
    "        if shape[\"label\"] == \"window\":  # Filter for \"window\" objects\n",
    "            points = shape[\"points\"]\n",
    "            x_coords = [p[0] for p in points]\n",
    "            y_coords = [p[1] for p in points]\n",
    "            x_min = min(x_coords)\n",
    "            y_min = min(y_coords)\n",
    "            x_max = max(x_coords)\n",
    "            y_max = max(y_coords)\n",
    "\n",
    "            # Convert to YOLO format [class_id, center_x, center_y, width, height]\n",
    "            center_x = ((x_min + x_max) / 2) / image_width\n",
    "            center_y = ((y_min + y_max) / 2) / image_height\n",
    "            width = (x_max - x_min) / image_width\n",
    "            height = (y_max - y_min) / image_height\n",
    "\n",
    "            yolo_annotations.append(f\"0 {center_x} {center_y} {width} {height}\")\n",
    "\n",
    "    return yolo_annotations\n",
    "\n",
    "# Load all image filenames and split into train/val sets\n",
    "image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "train_files, val_files = train_test_split(image_filenames, test_size=0.2, random_state=42)\n",
    "\n",
    "# Process and save train and val data\n",
    "for dataset, image_files, images_dir, labels_dir in [\n",
    "    (\"train\", train_files, train_images_dir, train_labels_dir),\n",
    "    (\"val\", val_files, val_images_dir, val_labels_dir)\n",
    "]:\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        annotation_path = os.path.join(annotation_dir, f\"{os.path.splitext(img_file)[0]}.json\")\n",
    "\n",
    "        # Copy image to output directory\n",
    "        shutil.copy(img_path, images_dir)\n",
    "\n",
    "        # Open image to get dimensions\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        # Convert annotations to YOLO format and save\n",
    "        yolo_annotations = convert_to_yolo_format(annotation_path, width, height)\n",
    "        label_path = os.path.join(labels_dir, f\"{os.path.splitext(img_file)[0]}.txt\")\n",
    "        with open(label_path, \"w\") as label_file:\n",
    "            label_file.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "print(f\"Dataset organized successfully!\")\n",
    "print(f\"Train images: {len(train_files)}, Validation images: {len(val_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
